{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c63984d-906c-4eed-ba23-405e3e5d89af",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is the relationship between polynomial functions and kernel functions in machine learning\n",
    "algorithms?\n",
    "Answer--Polynomial functions and kernel functions are both used in machine learning\n",
    "algorithms, particularly in support vector machines (SVMs) and kernel methods, but\n",
    "they serve different purposes and have different mathematical properties. However,\n",
    "there is a relationship between polynomial functions and kernel functions, especiall\n",
    "y when discussing polynomial kernel functions.\n",
    "\n",
    "Polynomial Functions:\n",
    "\n",
    "Polynomial functions are mathematical functions that involve variables raised to \n",
    "integer powers.\n",
    "In machine learning, polynomial functions are often used to create polynomial \n",
    "features from the original features of the dataset. For example, if you have a feature \n",
    "�\n",
    "x, a polynomial transformation might involve creating new features such as \n",
    "�\n",
    "2\n",
    "x \n",
    "2\n",
    " , \n",
    "�\n",
    "3\n",
    "x \n",
    "3\n",
    " , and so on.\n",
    "Polynomial functions are used for feature transformation, allowing algorithms to capture\n",
    "more complex relationships between the input features and the target variable.\n",
    "Kernel Functions:\n",
    "\n",
    "Kernel functions are mathematical functions used in kernel methods, including SVMs,\n",
    "to compute the similarity or distance between pairs of data points in a high-dimensional feature space.\n",
    "The most common kernel functions include linear kernels, polynomial kernels, Gaussian\n",
    "(radial basis function) kernels, and sigmoid kernels.\n",
    "Kernel functions allow algorithms to implicitly operate in a high-dimensional feature\n",
    "space without explicitly computing the transformations of the input features.\n",
    "The choice of kernel function determines the shape and complexity of the decision \n",
    "boundary learned by the algorithm.\n",
    "Polynomial Kernel Functions:\n",
    "\n",
    "Polynomial kernel functions are a type of kernel function used in SVMs and other\n",
    "kernel-based algorithms.\n",
    "Polynomial kernel functions compute the dot product between feature vectors in a\n",
    "higher-dimensional space, where the features are transformed using polynomial functions.\n",
    "The polynomial kernel function is defined as \n",
    "�\n",
    "(\n",
    "�\n",
    ",\n",
    "�\n",
    ")\n",
    "=\n",
    "(\n",
    "�\n",
    "⋅\n",
    "�\n",
    "+\n",
    "�\n",
    ")\n",
    "�\n",
    "K(x,y)=(x⋅y+c) \n",
    "d\n",
    " , where \n",
    "�\n",
    "x and \n",
    "�\n",
    "y are feature vectors, \n",
    "�\n",
    "c is a constant, and \n",
    "�\n",
    "d is the degree of the polynomial.\n",
    "The polynomial kernel function allows SVMs to learn nonlinear decision boundaries\n",
    "by implicitly mapping the input features into a higher-dimensional space using polynomial transformations.\n",
    "\n",
    "Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?\n",
    "Answer--\n",
    "To implement a Support Vector Machine (SVM) with a polynomial\n",
    "kernel in Python using Scikit-learn, you can use the SVC (Support Vector Classification) \n",
    "class from the sklearn.svm module. The SVC class allows you to specify a polynomial kernel\n",
    "by setting the kernel parameter to 'poly'. Additionally, you can configure other parameters \n",
    "such as the degree of the polynomial, regularization parameter \n",
    "�\n",
    "C, and other hyperparameters.\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # Consider only the first two features for visualization\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create an SVM classifier with a polynomial kernel\n",
    "poly_svm = make_pipeline(StandardScaler(), SVC(kernel='poly', degree=3, C=1.0))\n",
    "\n",
    "# Train the SVM classifier\n",
    "poly_svm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = poly_svm.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Plot decision boundaries\n",
    "h = .02  # step size in the mesh\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "Z = poly_svm.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.coolwarm, edgecolors='k', marker='o')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('SVM with Polynomial Kernel')\n",
    "plt.show()\n",
    "\n",
    "Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?\n",
    "Answer--\n",
    "In Support Vector Regression (SVR), the epsilon parameter (\n",
    "�\n",
    "ϵ) determines the width of the tube around the predicted function within which no \n",
    "penalty is associated with errors. It essentially defines the margin of tolerance \n",
    "within which errors are ignored.\n",
    "\n",
    "Here's how increasing the value of epsilon affects the number of support vectors in SVR:\n",
    "\n",
    "Decrease in Number of Support Vectors: As you increase the value of epsilon, you \n",
    "allow for a larger margin of tolerance for errors. This means that the SVR model \n",
    "becomes more lenient in terms of the errors it can tolerate within the margin. \n",
    "Consequently, fewer data points will be considered as support vectors because\n",
    "the model is allowed to have larger deviations from the actual data points.\n",
    "\n",
    "Increase in Margin of Tolerance: A larger epsilon value means a wider margin \n",
    "of tolerance around the regression line or hyperplane. As a result, the SVR\n",
    "model can fit the training data with larger deviations from the actual data\n",
    "points while still satisfying the margin constraints. This reduces the need \n",
    "for including more data points as support vectors to define the decision boundary.\n",
    "\n",
    "Smoother Predictions: With a larger epsilon, the SVR model tends to produce\n",
    "smoother predictions because it is less sensitive to individual data points. \n",
    "It focuses more on fitting the general trend of the data rather than trying to\n",
    "fit each data point precisely.\n",
    "\n",
    "Possible Underfitting: However, increasing epsilon too much can lead to underfitting,\n",
    "especially if the tolerance margin becomes too large relative to the variability in \n",
    "the data. In such cases, the SVR model may fail to capture important patterns or \n",
    "trends in the data, resulting in poor predictive performance.\n",
    "\n",
    "Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter\n",
    "affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works\n",
    "and provide examples of when you might want to increase or decrease its value?\n",
    "Answer--"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
